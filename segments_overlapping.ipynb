{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calling_redshift():\n",
    "    \"\"\"\n",
    "    This function connects to Amazon Redshift.\n",
    "    \"\"\"\n",
    "    con = psycopg2.connect(dbname='', \n",
    "                           host='', \n",
    "                           port='',\n",
    "                           user='',    \n",
    "                           password='')\n",
    "    return con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_maid_for_segments(start_date, end_date, min_lat, min_long, max_lat, max_long, start_hour, end_hour, country_iso3, segment_file):\n",
    "    \"\"\"\n",
    "    Retrieves the MAID for each segment and saves segments in separate files.\n",
    "    \"\"\"\n",
    "    segments_df = pd.read_csv(segment_file, header=None, skiprows=1)\n",
    "    segments = segments_df[0].tolist()\n",
    "\n",
    "    cur_profile_table = f\"cur_profile_segment_affinity_{country_iso3}\"\n",
    "    transdata_table = f\"transdata_{country_iso3}\"\n",
    "    \n",
    "    segment_placeholders = ','.join(['%s'] * len(segments))\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        data.segment AS name,       \n",
    "        data.maid\n",
    "    FROM\n",
    "        {cur_profile_table} AS data\n",
    "    JOIN (\n",
    "        SELECT DISTINCT\n",
    "            data.maid\n",
    "        FROM {transdata_table} AS data\n",
    "        WHERE (data.latitude > %s AND data.latitude < %s AND data.longitude > %s AND data.longitude < %s) \n",
    "            AND DATE(data.transaction_datetime) BETWEEN %s AND %s\n",
    "            AND EXTRACT(HOUR FROM data.transaction_datetime) BETWEEN %s AND %s\n",
    "    ) AS filtered_data ON data.maid = filtered_data.maid\n",
    "    WHERE data.segment IN ({segment_placeholders})  -- Filter segments based on CSV file\n",
    "    GROUP BY data.segment, data.maid;  -- Include data.maid in the GROUP BY clause\n",
    "    \"\"\"\n",
    "    \n",
    "    with calling_redshift() as con:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(query, (min_lat, max_lat, min_long, max_long, start_date, end_date, start_hour, end_hour) + tuple(segments))\n",
    "        df = pd.DataFrame(cur.fetchall(), columns=['name', 'maid'])\n",
    "\n",
    "    print(\"Retrieved data:\", df) \n",
    "    for segment_index, segment in enumerate(segments, start=1):\n",
    "        segment_df = df[df['name'] == segment]\n",
    "        segment_filename = f'/home/fazan123/MW/overlapping/New/{segment}.csv'\n",
    "        segment_df.to_csv(segment_filename, index=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Below Cell Update Custom Hours and Run to Calculate the Overlapping Probailities between only 2 segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def calc_prob(df):\n",
    "#     \"\"\"\n",
    "#     Calculates the probability of overlap between segments.\n",
    "#     \"\"\"\n",
    "#     seg1 = []\n",
    "#     seg2 = []\n",
    "#     prob_l = []\n",
    "#     seg_l = df['name'].unique()\n",
    "\n",
    "#     for i in range(len(seg_l)):\n",
    "#         tmp1 = df[df['name'] == seg_l[i]]\n",
    "#         maid_list1 = set(tmp1['maid'])\n",
    "\n",
    "#         for u in range(len(seg_l)):\n",
    "#             if seg_l[u] != seg_l[i]:\n",
    "#                 tmp2 = df[df['name'] == seg_l[u]]\n",
    "#                 maid_list2 = set(tmp2['maid'])\n",
    "\n",
    "#                 inter = maid_list1.intersection(maid_list2)\n",
    "\n",
    "#                 try:\n",
    "#                     prob = ((len(inter) / len(maid_list1)) + (len(inter) / len(maid_list2))) / 2\n",
    "#                     seg1.append(seg_l[i])\n",
    "#                     seg2.append(seg_l[u])\n",
    "#                     prob_l.append(prob)\n",
    "#                 except ZeroDivisionError:\n",
    "#                     pass\n",
    "\n",
    "#     final = pd.DataFrame(list(zip(seg1, seg2, prob_l)), columns=['segment1', 'segment2', 'Probability'])\n",
    "#     return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_lat = -6.2213\n",
    "# max_long = 106.8132\n",
    "# min_lat = -6.2303\n",
    "# min_long = 106.8042\n",
    "# start_date = '2024-02-22'\n",
    "# end_date = '2024-02-23'\n",
    "# start_hour = 0\n",
    "# end_hour = 10\n",
    "# country_iso3 = \"IDN\"\n",
    "# segment_file = \"/home/fazan123/MW/overlapping/sample_file/sample_segments.csv\"\n",
    "\n",
    "# df = retrieve_maid_for_segments(start_date, end_date, min_lat, min_long, max_lat, max_long, start_hour, end_hour, country_iso3, segment_file)\n",
    "# prob_df = calc_prob(df)\n",
    "# prob_df.to_csv(f'/home/fazan123/MW/overlapping/New/overlapping_segment_probabilities_in_{country_iso3}_from_{start_date}_to_{end_date}_between_{start_hour}_and_{end_hour}_for_custom_segments.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Below Cell Update values  and Run to Calculate the Overlapping Probailities between all combinations of segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob_for_all_combinations(df, output_dir):\n",
    "    \"\"\"\n",
    "    Calculates the probability of overlap between segments for combinations of segments and writes the results to a CSV file.\n",
    "    \"\"\"\n",
    "    prob_data = []\n",
    "    seg_l = df['name'].unique()\n",
    "\n",
    "    for n_segments in range(2, len(seg_l) + 1):\n",
    "        for combination in itertools.combinations(seg_l, n_segments):\n",
    "            maid_sets = [set(df[df['name'] == segment]['maid']) for segment in combination]\n",
    "            intersection = set.intersection(*maid_sets)\n",
    "            try:\n",
    "                prob = sum(len(intersection) / len(maid_set) for maid_set in maid_sets) / n_segments\n",
    "                prob_data.append((','.join(combination), prob))\n",
    "            except ZeroDivisionError:\n",
    "                pass\n",
    "\n",
    "    final = pd.DataFrame(prob_data, columns=['Segments', 'Overlap Percentage'])\n",
    "\n",
    "    output_file = os.path.join(output_dir, 'overlap_probabilities_for_all_combinations_of_segments.csv')\n",
    "    final.to_csv(output_file, index=False)\n",
    "    print(f\"Output saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved data:                   name                                       maid\n",
      "0      cat_fashionista  GAID_1e184477-6f02-4abb-af70-287d8e3df8b1\n",
      "1      cat_fashionista  GAID_4c6b630c-8208-43ba-b87f-7460f85e3476\n",
      "2      cat_fashionista  GAID_9615d3e8-c7ca-4d18-bbd2-d5c83f62b7bf\n",
      "3      cat_fashionista  GAID_04e20c6e-3dc6-46f7-b4a3-922f25d6c50e\n",
      "4      cat_fashionista  GAID_4b1697ce-0248-60f0-2436-8dc21f6a1874\n",
      "...                ...                                        ...\n",
      "2990  cat_white_collar  GAID_341e427b-4e15-488e-aa97-3d599f31f2a7\n",
      "2991   cat_fashionista  GAID_49552864-4269-44d5-852f-921f7819a2b6\n",
      "2992   cat_fashionista  GAID_6ce477df-2af5-4f64-be4a-fb80da7b1a67\n",
      "2993   cat_fashionista  GAID_7a87a2b8-b6a0-4676-bf8b-729ea0a44bc0\n",
      "2994   cat_fashionista  GAID_8f16b9bf-7aee-4bbc-aec3-676e2492f2bc\n",
      "\n",
      "[2995 rows x 2 columns]\n",
      "Output saved to: /home/fazan123/MW/overlapping/New/overlap_probabilities_for_all_combinations_of_segments.csv\n"
     ]
    }
   ],
   "source": [
    "start_date = '2024-02-22'\n",
    "end_date = '2024-02-23'\n",
    "min_lat = -6.2303\n",
    "min_long = 106.8042\n",
    "max_lat = -6.2213\n",
    "max_long = 106.8132\n",
    "start_hour = 0\n",
    "end_hour = 10\n",
    "country_iso3 = \"IDN\"\n",
    "segment_file = \"/home/fazan123/MW/overlapping/sample_file/sample_segments.csv\"\n",
    "output_dir = \"/home/fazan123/MW/overlapping/New\"\n",
    "df = retrieve_maid_for_segments(start_date, end_date, min_lat, min_long, max_lat, max_long, start_hour, end_hour, country_iso3, segment_file)\n",
    "calc_prob_for_all_combinations(df, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
